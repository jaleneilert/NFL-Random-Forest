{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOe4RPLTA61HQqaJL/cLPhm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "NFL passing stats with k-fold cross validation by time series split (continuation of my final project)"
      ],
      "metadata": {
        "id": "bzEyFvLo3qYa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ieYpDLV3pmV",
        "outputId": "239e3207-8201-4157-91b6-adec9b634da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "passing_data = np.array(pd.read_csv('/content/drive/My Drive/KSU-MachineLearning/FinalProject/passing_cleaned.csv'))\n",
        "\n",
        "# index of touchdowns is 10, this will be our Y\n",
        "y = passing_data[:, 10]\n",
        "print(f'The y matrix : {y}')\n",
        "\n",
        "# We want X to not include index 0 (data point number), index 10 (passing touchdown), and index 11 (touchdown %)\n",
        "indices_to_delete = [0, 10, 11]\n",
        "\n",
        "X = np.delete(passing_data, indices_to_delete, 1)\n",
        "\n",
        "# grab the different teams and names so we can encode them\n",
        "categorical_indeces = np.array([0, 1])\n",
        "numerical_indeces = np.array(list(range(2, 24)))\n",
        "\n",
        "categorical_data = np.delete(X, numerical_indeces, 1)\n",
        "numerical_data = np.delete(X, categorical_indeces, 1)\n",
        "print(categorical_data)\n",
        "print(numerical_data)\n",
        "\n",
        "#encode names\n",
        "encoded_categorical1 = LabelEncoder().fit_transform(categorical_data[:,0]).reshape(-1,1)\n",
        "print(encoded_categorical1)\n",
        "\n",
        "#encode teams\n",
        "encoded_categorical2 = LabelEncoder().fit_transform(categorical_data[:,1]).reshape(-1,1)\n",
        "\n",
        "encoded_categorical = np.concatenate((encoded_categorical1, encoded_categorical2), axis=1)\n",
        "\n",
        "# combine them back (concatenate side by side)\n",
        "X_transform = np.concatenate((encoded_categorical, numerical_data), axis=1)\n",
        "column_names = ['Player','Tm', 'Age', 'G', 'GS', 'Cmp', 'Att', 'Cmp%', 'Yds', 'Int', 'Int%', '1D', 'Lng', 'Y/A', 'AY/A', 'Y/C', 'Y/G', 'Rate', 'Sk', 'Yds-s', 'Sk%', 'NY/A', 'ANY/A', 'Yea']\n",
        "print(len(column_names))\n",
        "print(X_transform)\n",
        "print(X_transform.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jw2nTUC35ns",
        "outputId": "1d807998-0cac-4d37-dddd-ce6923a0d2bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The y matrix : [36 26 32 ... 0 0 0]\n",
            "[['Kurt Warner' 'STL']\n",
            " ['Peyton Manning' 'IND']\n",
            " ['Brett Favre' 'GNB']\n",
            " ...\n",
            " ['Garrett Wilson' 'NYJ']\n",
            " ['Christian Kirk' 'JAX']\n",
            " [\"Ja'Marr Chase\" 'CIN']]\n",
            "[[30 16 16 ... 7.87 7.41 2001]\n",
            " [25 16 16 ... 6.77 5.88 2001]\n",
            " [32 16 16 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [23 17 17 ... 0.0 0.0 2023]\n",
            " [27 12 12 ... -0.5 -0.5 2023]\n",
            " [23 16 16 ... -7.0 -7.0 2023]]\n",
            "[[423]\n",
            " [544]\n",
            " [ 74]\n",
            " ...\n",
            " [270]\n",
            " [143]\n",
            " [290]]\n",
            "24\n",
            "[[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [270 26 23 ... 0.0 0.0 2023]\n",
            " [143 16 27 ... -0.5 -0.5 2023]\n",
            " [290 8 23 ... -7.0 -7.0 2023]]\n",
            "(2350, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will use time series split to the split the data it to different years."
      ],
      "metadata": {
        "id": "-8eAnD5U5Lfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
        "\n",
        "clf = RandomForestRegressor(oob_score=True, n_estimators=175, max_depth = 20, criterion = 'absolute_error')\n",
        "\n",
        "ts_split = TimeSeriesSplit(n_splits=8, max_train_size=None, test_size=None, gap =0)\n",
        "for fold, (train_index, test_index) in enumerate(ts_split.split(X_transform, y)):\n",
        "  Xtrain, Xtest = X_transform[train_index], X_transform[test_index]\n",
        "  ytrain, ytest = y[train_index], y[test_index]\n",
        "  print(f'Fold X: {Xtrain}')\n",
        "  print(\"end x fold\")\n",
        "  print(Xtest)\n",
        "  print(\"done printing Xtest\")\n",
        "\n",
        "  clf.fit(Xtrain, ytrain)\n",
        "\n",
        "  if(fold == 1):\n",
        "    y_manninghat = clf.predict(X_transform[344].reshape(1,-1)) #Peyton Manning 2004\n",
        "    print(f'Models Manning TD Error in 2004: {y[344] - y_manninghat}')\n",
        "  if(fold == 2):\n",
        "    y_manninghat = clf.predict(X_transform[560].reshape(1,-1)) #Peyton Manning 2006\n",
        "    print(f'Models Manning TD Error in 2006: {y[560] - y_manninghat}')\n",
        "  if(fold == 3):\n",
        "    y_manninghat = clf.predict(X_transform[871].reshape(1,-1)) #Peyton Manning 2009\n",
        "    print(f'Models Manning TD Error in 2009:{y[871] - y_manninghat}')\n",
        "  if(fold == 4):\n",
        "    y_manninghat = clf.predict(X_transform[1187].reshape(1,-1)) #Peyton Manning 2012\n",
        "    print(f'Models Manning TD Error in 2012:{y[1187] - y_manninghat}')\n",
        "\n",
        "\n",
        "  y_hat = clf.predict(Xtest)\n",
        "\n",
        "  oob_score_def = clf.oob_score_\n",
        "  print(f'The Out Of Bag score is {oob_score_def}')\n",
        "\n",
        "  mse_def = mean_squared_error(ytest, y_hat)\n",
        "  print(f'The mean squared error is {mse_def}')\n",
        "\n",
        "  rmse_def = root_mean_squared_error(ytest, y_hat)\n",
        "  print(f'The root mean squared error is {rmse_def}')\n",
        "\n",
        "  r2_def = r2_score(ytest, y_hat)\n",
        "  print(f'The r2 score is {r2_def}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io3pStq75rYL",
        "outputId": "9fc1a034-146c-447f-86bb-c9bb31b8f058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [49 35 27 ... 6.67 7.13 2003]\n",
            " [343 25 25 ... 3.31 2.4 2003]\n",
            " [463 16 33 ... 4.81 5.25 2003]]\n",
            "end x fold\n",
            "[[183 11 30 ... 3.98 2.22 2003]\n",
            " [564 7 23 ... 5.21 5.14 2003]\n",
            " [422 3 23 ... 3.03 1.1 2003]\n",
            " ...\n",
            " [142 6 33 ... 4.92 6.46 2005]\n",
            " [176 12 22 ... 3.33 3.33 2005]\n",
            " [327 7 35 ... 6.11 8.33 2005]]\n",
            "done printing Xtest\n",
            "The Out Of Bag score is 0.9381650857468886\n",
            "The mean squared error is 4.841823316912973\n",
            "The root mean squared error is 2.2004143511877423\n",
            "The r2 score is 0.9347332723787573\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [142 6 33 ... 4.92 6.46 2005]\n",
            " [176 12 22 ... 3.33 3.33 2005]\n",
            " [327 7 35 ... 6.11 8.33 2005]]\n",
            "end x fold\n",
            "[[432 30 26 ... 11.75 26.75 2005]\n",
            " [236 24 43 ... 1.45 1.45 2005]\n",
            " [35 32 25 ... 13.5 13.5 2005]\n",
            " ...\n",
            " [216 9 25 ... 5.14 4.54 2008]\n",
            " [614 31 28 ... 5.69 6.02 2008]\n",
            " [598 14 30 ... 7.5 5.7 2008]]\n",
            "done printing Xtest\n",
            "Models Manning TD Error in 2004: [1.]\n",
            "The Out Of Bag score is 0.9401942187256962\n",
            "The mean squared error is 4.9613257956056\n",
            "The root mean squared error is 2.22740337514461\n",
            "The r2 score is 0.9438728781475951\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [216 9 25 ... 5.14 4.54 2008]\n",
            " [614 31 28 ... 5.69 6.02 2008]\n",
            " [598 14 30 ... 7.5 5.7 2008]]\n",
            "end x fold\n",
            "[[483 31 33 ... 4.81 3.28 2008]\n",
            " [79 34 33 ... 5.2 4.09 2008]\n",
            " [640 22 25 ... 5.88 6.44 2008]\n",
            " ...\n",
            " [630 2 27 ... 8.5 8.5 2010]\n",
            " [126 23 24 ... 1.5 1.5 2010]\n",
            " [543 9 24 ... 6.5 6.5 2010]]\n",
            "done printing Xtest\n",
            "Models Manning TD Error in 2006: [0.57714286]\n",
            "The Out Of Bag score is 0.9448786134776886\n",
            "The mean squared error is 3.46289411212761\n",
            "The root mean squared error is 1.8608853033240953\n",
            "The r2 score is 0.9596256725359251\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [630 2 27 ... 8.5 8.5 2010]\n",
            " [126 23 24 ... 1.5 1.5 2010]\n",
            " [543 9 24 ... 6.5 6.5 2010]]\n",
            "end x fold\n",
            "[[603 4 28 ... 13.0 13.0 2010]\n",
            " [49 30 34 ... 8.0 8.0 2010]\n",
            " [395 26 27 ... 3.0 3.0 2010]\n",
            " ...\n",
            " [375 26 30 ... 12.67 12.67 2013]\n",
            " [227 3 24 ... 4.86 4.86 2013]\n",
            " [476 29 34 ... 30.0 30.0 2013]]\n",
            "done printing Xtest\n",
            "Models Manning TD Error in 2009:[0.93142857]\n",
            "The Out Of Bag score is 0.9516880202938212\n",
            "The mean squared error is 6.67616442255063\n",
            "The root mean squared error is 2.583827475384266\n",
            "The r2 score is 0.9493198664639955\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [375 26 30 ... 12.67 12.67 2013]\n",
            " [227 3 24 ... 4.86 4.86 2013]\n",
            " [476 29 34 ... 30.0 30.0 2013]]\n",
            "end x fold\n",
            "[[47 26 25 ... 30.0 30.0 2013]\n",
            " [522 8 24 ... 25.0 25.0 2013]\n",
            " [458 27 28 ... 22.0 22.0 2013]\n",
            " ...\n",
            " [610 15 29 ... 4.88 3.13 2016]\n",
            " [245 2 32 ... 3.76 1.82 2016]\n",
            " [123 9 34 ... 6.46 5.5 2016]]\n",
            "done printing Xtest\n",
            "Models Manning TD Error in 2012:[0.14285714]\n",
            "The Out Of Bag score is 0.9584246343117142\n",
            "The mean squared error is 6.439205661115022\n",
            "The root mean squared error is 2.5375589965782117\n",
            "The r2 score is 0.9524668809907874\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [610 15 29 ... 4.88 3.13 2016]\n",
            " [245 2 32 ... 3.76 1.82 2016]\n",
            " [123 9 34 ... 6.46 5.5 2016]]\n",
            "end x fold\n",
            "[[156 27 23 ... 6.22 5.13 2016]\n",
            " [688 31 23 ... 7.37 6.05 2016]\n",
            " [250 5 26 ... 3.83 3.83 2016]\n",
            " ...\n",
            " [430 2 22 ... 5.78 5.55 2019]\n",
            " [418 22 31 ... 7.2 7.73 2019]\n",
            " [588 21 37 ... 6.13 5.78 2019]]\n",
            "done printing Xtest\n",
            "The Out Of Bag score is 0.9579154114047401\n",
            "The mean squared error is 5.370259191492689\n",
            "The root mean squared error is 2.317381969268918\n",
            "The r2 score is 0.9560465124256405\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [430 2 22 ... 5.78 5.55 2019]\n",
            " [418 22 31 ... 7.2 7.73 2019]\n",
            " [588 21 37 ... 6.13 5.78 2019]]\n",
            "end x fold\n",
            "[[22 8 32 ... 5.74 5.19 2019]\n",
            " [424 6 23 ... 5.47 4.76 2019]\n",
            " [268 16 23 ... 6.14 6.44 2019]\n",
            " ...\n",
            " [282 23 23 ... 2.89 -0.32 2021]\n",
            " [424 36 25 ... 5.48 6.43 2021]\n",
            " [116 10 26 ... 29.33 29.33 2021]]\n",
            "done printing Xtest\n",
            "The Out Of Bag score is 0.9599532877197245\n",
            "The mean squared error is 5.560156009070295\n",
            "The root mean squared error is 2.3579983055698523\n",
            "The r2 score is 0.9562486109793014\n",
            "Fold X: [[423 33 30 ... 7.87 7.41 2001]\n",
            " [544 15 25 ... 6.77 5.88 2001]\n",
            " [74 13 32 ... 7.09 7.02 2001]\n",
            " ...\n",
            " [282 23 23 ... 2.89 -0.32 2021]\n",
            " [424 36 25 ... 5.48 6.43 2021]\n",
            " [116 10 26 ... 29.33 29.33 2021]]\n",
            "end x fold\n",
            "[[117 17 36 ... 5.13 5.13 2021]\n",
            " [667 12 25 ... 75.0 95.0 2021]\n",
            " [50 34 32 ... 4.75 4.75 2021]\n",
            " ...\n",
            " [270 26 23 ... 0.0 0.0 2023]\n",
            " [143 16 27 ... -0.5 -0.5 2023]\n",
            " [290 8 23 ... -7.0 -7.0 2023]]\n",
            "done printing Xtest\n",
            "The Out Of Bag score is 0.9608858825827539\n",
            "The mean squared error is 2.0432637422785205\n",
            "The root mean squared error is 1.4294277674225166\n",
            "The r2 score is 0.9759335185395912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.403 rmse very nice :)"
      ],
      "metadata": {
        "id": "b17SxbDuHkD2"
      }
    }
  ]
}